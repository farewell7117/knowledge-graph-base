{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Network Embedding for Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch, torch.nn as nn, torch.autograd as autograd\n",
    "import torch.utils.data\n",
    "from torch.distributions import multivariate_normal\n",
    "\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import citation_graph as citegrh\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import mixture\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = citegrh.load_cora()\n",
    "G    = DGLGraph(data.graph)\n",
    "kn   = G.to_networkx()\n",
    "pos  = nx.spring_layout(kn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N    = 2708\n",
    "D    = 400\n",
    "K    = 7\n",
    "eps  = 1e-6\n",
    "beta = 1e-4\n",
    "\n",
    "batch_size = 300\n",
    "\n",
    "# FIXME: restrict propbability density functions\n",
    "max_density = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(row):\n",
    "    return np.array(row.split(\" \")).astype(float)\n",
    "\n",
    "def normalize(v):\n",
    "    min_v = torch.min(v)\n",
    "    range_v = torch.max(v) - min_v\n",
    "    \n",
    "    if range_v > 0:\n",
    "        return (v - min_v) / range_v\n",
    "    else:\n",
    "        return torch.zeros(vector.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipgram2dict(skipgram):\n",
    "    d = dict(skipgram[i].split(\" \", 1) for i in range(len(skipgram)))\n",
    "    d = {int(num): vectorize(v) for num, v in d.items()}\n",
    "    \n",
    "    return collections.OrderedDict(sorted(d.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans(x, K, Niter=10, verbose=False):\n",
    "    N, D = x.shape # Number of samples, dimension of the ambient space\n",
    "\n",
    "    # K-means loop:\n",
    "    # - x  is the point cloud,\n",
    "    # - cl is the vector of class labels\n",
    "    # - c  is the cloud of cluster centroids\n",
    "    start = time.time()\n",
    "    c     = x[:K, :].clone().detach() # Simplistic random initialization\n",
    "    x_i   = torch.clone(x[:, None, :]).detach() # (Npoints, 1, D)\n",
    "\n",
    "    for i in range(Niter):\n",
    "\n",
    "        c_j  = torch.clone(c[None, :, :]).detach() # (1, Nclusters, D)\n",
    "        D_ij = ((x_i - c_j) ** 2).sum(-1) # (Npoints, Nclusters) symbolic matrix of squared distances\n",
    "        cl   = D_ij.argmin(dim=1).long().view(-1) # Points -> Nearest cluster\n",
    "        pi   = 1 - normalize(D_ij)\n",
    "\n",
    "        Ncl = torch.bincount(cl).float() # Class weights\n",
    "        for d in range(D): # Compute the cluster centroids with torch.bincount:\n",
    "            c[:, d] = torch.bincount(cl, weights=x[:, d]) / Ncl\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"K-means example with {:,} points in dimension {:,}, K = {:,}:\".format(N, D, K))\n",
    "        print('Timing for {} iterations: {:.5f}s = {} x {:.5f}s\\n'.format(\n",
    "                Niter, end - start, Niter, (end - start) / Niter))\n",
    "\n",
    "    return cl, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Embedding ([ComE](https://sentic.net/community-embedding.pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model, gmm, X_batch, pi, psi, Sigma):\n",
    "    X = model(X_batch)\n",
    "    \n",
    "    # Probabilities (X_batch, K)\n",
    "    probs = torch.FloatTensor(gmm.predict_proba(X)).clamp(min=eps)\n",
    "    # Gamma (X_batch, K)\n",
    "    gamma = compute_gamma(pi, probs)\n",
    "    # N (1, K)\n",
    "    N     = gamma.sum(dim=0, keepdim=True)\n",
    "    # Pi (1, K)\n",
    "    pi    = N / X_batch.size(0)\n",
    "    \n",
    "    gmm.fit(X.numpy())\n",
    "    \n",
    "    # Psi (K)\n",
    "    psi   = torch.FloatTensor(gmm.means_)\n",
    "    # Sigma (K)\n",
    "    Sigma = torch.FloatTensor(gmm.covariances_)\n",
    "    \n",
    "    loss  = -(beta / K) * torch.sum(torch.sum(torch.log(pi * probs), dim=1, keepdim=True))\n",
    "    \n",
    "    return psi, Sigma, loss\n",
    "\n",
    "def compute_gamma(pi, probs):\n",
    "    gamma_numerator   = pi * probs\n",
    "    gamma_denominator = torch.sum(gamma_numerator, dim=1, keepdim=True)\n",
    "    \n",
    "    return torch.div(gamma_numerator, gamma_denominator)\n",
    "\n",
    "def reset_embeddings(X_batch, K):\n",
    "    data = X_batch.clone().detach().numpy()\n",
    "    gmm  = mixture.GaussianMixture(n_components=K, covariance_type='diag').fit(data)\n",
    "    \n",
    "    return torch.FloatTensor(gmm.means_), torch.FloatTensor(gmm.covariances_), gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(400, 1024),\n",
    "    nn.Dropout(0.05),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.Dropout(0.05),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.Dropout(0.05),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 400)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!deepwalk --help\n",
    "\n",
    "#!deepwalk --input ../graphsage/cora/cora.adjlist --representation-size 400 --walk-length 40 --output ../graphsage/cora/cora.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../graphsage/cora/cora.embeddings\", \"r\") as f:\n",
    "    skipgram = f.readlines()\n",
    "    skipgram.pop(0)\n",
    "    dataset = skipgram2dict(skipgram)\n",
    "    x       = torch.FloatTensor(list(dataset.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_gen = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "psi, Sigma, gmm = reset_embeddings(x, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train(True)\n",
    "    \n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    \n",
    "    for X_batch in train_batch_gen:\n",
    "        with autograd.detect_anomaly():\n",
    "            # Obtain mixed-community membership\n",
    "            l, pi            = KMeans(X_batch, K)\n",
    "            # Update pi, mean, cov\n",
    "            psi, Sigma, loss = compute_loss(model, gmm, X_batch.float(), pi.float(), psi, Sigma)\n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "            \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        train_loss.append(loss.data.cpu().numpy())\n",
    "        \n",
    "    print(\"Training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(dataset) // batch_size :]))\n",
    "    )\n",
    "\n",
    "model.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = nx.draw_networkx_nodes(kn, pos, node_color=data.labels,\n",
    "                            with_labels=False, node_size=0.5, cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2, pi2 = KMeans(x, K, Niter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = nx.draw_networkx_nodes(kn, pos, node_color=labels2,\n",
    "                            with_labels=False, node_size=0.5, cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels3, pi3 = KMeans(model(x), K, Niter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = nx.draw_networkx_nodes(kn, pos, node_color=labels3,\n",
    "                            with_labels=False, node_size=0.5, cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual info score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_mutual_info_score(labels.flatten(), labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_mutual_info_score(labels.flatten(), labels3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
